{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Business Vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the section *\"Define Business Vocabulary\"* of the [Level 4 PoX - Knowledge Catalog Tutorial](https://cp4d-outcomes.techzone.ibm.com/l4-pox/knowledge-catalog) and uses the [Watson Data API](https://cloud.ibm.com/apidocs/watson-data-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorisation - mandatory customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing the next cell, observe the variables `LOCAL_DIR_PREFIX` and `FILE_CREDENTIALS` and adjust them to your environment. If they are set wrong, the csv files containing the artifact definitions or your credentials in a file (in case you want to use one) will not be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests # type: ignore\n",
    "import time\n",
    "\n",
    "LOCAL_DIR_PREFIX = \"\"\n",
    "\n",
    "# uncomment the next line if you cloned the repository and the notebook will run locally on your laptop\n",
    "LOCAL_DIR_PREFIX = \"../../\"\n",
    "\n",
    "# uncomment the next line if hardcoding the credentials on the code, global class variables\n",
    "FILE_CREDENTIALS = \"\"\n",
    "\n",
    "# uncomment the next two lines if using the file ikcapikey.json for storing credentials\n",
    "# FILE_CREDENTIALS = \"python/ikcapikey.json\"\n",
    "# FILE_CREDENTIALS = LOCAL_DIR_PREFIX + FILE_CREDENTIALS\n",
    "\n",
    "class credentials :\n",
    "\n",
    "    file_credentials = \"\"\n",
    "    url_server = \"https://cpd-cpd.apps.6645c6d6ca5b92001e29286f.cloud.techzone.ibm.com\"\n",
    "    username = \"admin\"\n",
    "    apikey = \"SfpLD0yMQFh4xpdOrgPuTK9AdBtEVEqF1gK2HSlw\"\n",
    "    access_token = \"\"\n",
    "\n",
    "    def __init__(self, file_credentials):\n",
    "\n",
    "        if file_credentials != \"\" :\n",
    "            try :\n",
    "                with open(file_credentials) as f :\n",
    "                    data = json.load(f)\n",
    "                    self.url_server = data[\"url_server\"]\n",
    "                    self.username = data[\"username\"]\n",
    "                    self.apikey = data[\"api_key\"]\n",
    "                    self.file_credentials = file_credentials\n",
    "            except :\n",
    "                print(\"Error with the file \", file_credentials)\n",
    "    \n",
    "   \n",
    "    def urlRequest(self, urlSuffix):\n",
    "        return self.url_server + urlSuffix\n",
    "\n",
    "    def get_bearer_token(self):\n",
    "        \n",
    "        # Get a bearer token with the API key - Cloud Pak for Data SaaS\n",
    "        # url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "        # headers = {\"Content-Type\" : \"application/x-www-form-urlencoded\"}\n",
    "        # data = \"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey=\" + apikey\n",
    "        # r = requests.post(url, headers=headers, data=data)\n",
    "        # access_token = r.json()[\"access_token\"]\n",
    "\n",
    "        # Get a bearer token with the API key - Cloud Pak for Data Software\n",
    "        urlSuffix = \"/icp4d-api/v1/authorize\"\n",
    "        headers = {'Accept': 'application/json', 'Content-type': 'application/json'}\n",
    "        data = {\"username\" : self.username, \"api_key\" : self.apikey}\n",
    "        r = requests.post(self.urlRequest(urlSuffix), headers=headers, data=json.dumps(data))\n",
    "\n",
    "        if r.status_code != 200:\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "        else :\n",
    "            try:\n",
    "                self.access_token = r.json()[\"token\"]\n",
    "            except KeyError:\n",
    "                print(\"Error with the token. Code: \", r.status_code)\n",
    "                print(\"Hint: check the credentials file \", self.file_credentials)\n",
    "                print(r.text)\n",
    "                \n",
    "            return self.access_token\n",
    "\n",
    "myconn = credentials(FILE_CREDENTIALS)\n",
    "access_token = myconn.get_bearer_token()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Business Vocabulary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can follow one by one the tasks as indicated in the PoX instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Categories\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Import Categories from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-categories.csv\"\n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "urlSuffix='/v3/governance_artifact_types/category/import?merge_option=all'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "files = {'file': (IMPORT_CSV_FILE, open(IMPORT_CSV_FILE, 'rb'), 'text/csv')}\n",
    "\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    status = r.json()[\"status\"]\n",
    "    print(\"Import finished. Status = \", status)\n",
    "    print(r.text)\n",
    "elif r.status_code == 202 :\n",
    "    process_id = r.json()[\"process_id\"]\n",
    "    print(f\"----- Import process started: {process_id} ----- \")\n",
    "    print(\"----- Entering wait loop ------\")\n",
    "    urlSuffix='/v3/governance_artifact_types/import/status/' + process_id\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "    while True :\n",
    "        r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "        if r.status_code != 200 :\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "        status = r.json()[\"status\"]\n",
    "        if status != \"IN_PROGRESS\" :\n",
    "            break\n",
    "        else :\n",
    "            print (\"Import in progess, please wait\")\n",
    "            time.sleep(5)\n",
    "else :\n",
    "    print(\"Error with the request. Code: \", r.status_code)\n",
    "    print(r.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Update Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a. Change the definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Update Classifications from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-classifications.csv\" \n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "urlSuffix='/v3/governance_artifact_types/classification/import?merge_option=specified'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "files = {'file': (IMPORT_CSV_FILE, open(IMPORT_CSV_FILE, 'rb'), 'text/csv')}\n",
    "\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    status = r.json()[\"status\"]\n",
    "    print(\"Import finished. Status = \", status)\n",
    "    print(r.text)\n",
    "\n",
    "elif r.status_code == 202 :\n",
    "    process_id = r.json()[\"process_id\"]\n",
    "    print(f\"----- Import process started: {process_id} ----- \")\n",
    "    print(\"----- Entering wait loop ------\")\n",
    "    urlSuffix='/v3/governance_artifact_types/import/status/' + process_id\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "    while True :\n",
    "        r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "        if r.status_code != 200 :\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "            break\n",
    "        status = r.json()[\"status\"]\n",
    "        if status != \"IN_PROGRESS\" :\n",
    "            break\n",
    "        else :\n",
    "            print (\"Import in progess, please wait\")\n",
    "            time.sleep(5)\n",
    "else :\n",
    "    print(\"Error with the request. Code: \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "workflow_id = r.json()[\"workflow_id\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b. Publish the definitions\n",
    "\n",
    "Before executing this cell, you may want to check the \"Task Inbox\" in CloudPak for Data if you are not sure about what will be published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Data Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a. Add new Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Create Data Classes from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-data-classes.csv\" \n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "urlSuffix='/v3/governance_artifact_types/data_class/import?merge_option=all'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "files = {'file': (IMPORT_CSV_FILE, open(IMPORT_CSV_FILE, 'rb'), 'text/csv')}\n",
    "\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    status = r.json()[\"status\"]\n",
    "    print(\"Import finished. Status = \", status)\n",
    "    print(r.text)\n",
    "\n",
    "elif r.status_code == 202 :\n",
    "    process_id = r.json()[\"process_id\"]\n",
    "    print(f\"----- Import process started: {process_id} ----- \")\n",
    "    print(\"----- Entering wait loop ------\")\n",
    "    urlSuffix='/v3/governance_artifact_types/import/status/' + process_id\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "    while True :\n",
    "        r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "        if r.status_code != 200 :\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "            break\n",
    "        status = r.json()[\"status\"]\n",
    "        if status != \"IN_PROGRESS\" :\n",
    "            break\n",
    "        else :\n",
    "            print (\"Import in progess, please wait\")\n",
    "            time.sleep(5)\n",
    "else :\n",
    "    print(\"Error with the request. Code: \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "workflow_id = r.json()[\"workflow_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.b. Publish the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Business Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.a. Add new Business Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Create Business Terms from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-business-terms.csv\"\n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "urlSuffix='/v3/governance_artifact_types/glossary_term/import?merge_option=all'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "files = {'file': (IMPORT_CSV_FILE, open(IMPORT_CSV_FILE, 'rb'), 'text/csv')}\n",
    "\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    status = r.json()[\"status\"]\n",
    "    print(\"Import finished. Status = \", status)\n",
    "\n",
    "elif r.status_code == 202 :\n",
    "    process_id = r.json()[\"process_id\"]\n",
    "    print(f\"----- Import process started: {process_id} ----- \")\n",
    "    print(\"----- Entering wait loop ------\")\n",
    "    urlSuffix='/v3/governance_artifact_types/import/status/' + process_id\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "    while True :\n",
    "        r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "        if r.status_code != 200 :\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "            break\n",
    "        status = r.json()[\"status\"]\n",
    "        if status != \"IN_PROGRESS\" :\n",
    "            break\n",
    "        else :\n",
    "            print (\"Import in progess, please wait\")\n",
    "            time.sleep(5)\n",
    "else :\n",
    "    print(\"Error with the request. Code: \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "workflow_id = r.json()[\"workflow_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.b. Publish the changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Reference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.a Add new Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Create Reference Data from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-reference-data.csv\"\n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "urlSuffix='/v3/governance_artifact_types/reference_data/import?merge_option=all'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "files = {'file': (IMPORT_CSV_FILE, open(IMPORT_CSV_FILE, 'rb'), 'text/csv')}\n",
    "\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    status = r.json()[\"status\"]\n",
    "    print(\"Import finished. Status = \", status)\n",
    "\n",
    "elif r.status_code == 202 :\n",
    "    process_id = r.json()[\"process_id\"]\n",
    "    print(f\"----- Import process started: {process_id} ----- \")\n",
    "    print(\"----- Entering wait loop ------\")\n",
    "    urlSuffix='/v3/governance_artifact_types/import/status/' + process_id\n",
    "    headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "    while True :\n",
    "        r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "        if r.status_code != 200 :\n",
    "            print(\"Error with the request. Code: \", r.status_code)\n",
    "            print(r.text)\n",
    "            break\n",
    "        status = r.json()[\"status\"]\n",
    "        if status != \"IN_PROGRESS\" :\n",
    "            break\n",
    "        else :\n",
    "            print (\"Import in progess, please wait\")\n",
    "            time.sleep(5)\n",
    "else :\n",
    "    print(\"Error with the request. Code: \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "workflow_id = r.json()[\"workflow_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.b Publish the changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Load Department Lookup Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.a Add the lookup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---- Load Department Lookup Data from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-reference-department.csv\"\n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "artifact_id = None\n",
    "version_id = None\n",
    "urlSuffix='/v3/governance_artifact_types/reference_data?workflow_status=published&limit=200'\n",
    "headers = {\"accept\": \"application/json\" ,\"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    for i in r.json()[\"resources\"] :\n",
    "        if i[\"name\"] == \"Department Lookup\" :\n",
    "            artifact_id = i[\"artifact_id\"]\n",
    "            version_id = i[\"version_id\"]\n",
    "            print(\"artifact_id = \", artifact_id, \" version_id = \" , version_id)\n",
    "            break\n",
    "else :\n",
    "    print(\"Error in retrieving reference data artifacts, Code = \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "if artifact_id is None or version_id is None:\n",
    "    print(\"Department Lookup not found\")\n",
    "else :    \n",
    "    urlSuffix='/v4/reference_data_sets/' + artifact_id + '/versions/' + version_id + '/value_imports'\n",
    "    headers = {\"Authorization\" : \"Bearer \" + access_token }\n",
    "    import_parameters = {\n",
    "        \"artifact_id_mode\": False,\n",
    "        \"code\": \"DEPARTMENT_CODE\",\n",
    "        \"first_row_header\": True,\n",
    "        \"import_relationships_only\": False,\n",
    "        \"skip_workflow_if_possible\": False, \n",
    "        \"trim_white_spaces\": True,\n",
    "        \"value\": \"DEPARTMENT_EN\",\n",
    "        \"value_conflicts\": \"OVERWRITE\" \n",
    "    }\n",
    "    files={\n",
    "        'import_csv_file'   : ('import_csv_file', open(IMPORT_CSV_FILE,'rb') ),\n",
    "        'import_parameters' : (None, str(import_parameters))   \n",
    "    }\n",
    "    \n",
    "    r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "    if r.status_code == 202 :\n",
    "        import_id = r.json()[\"import_info\"][\"import_id\"]\n",
    "        print(f\"----- Import process started: {import_id} ----- \")\n",
    "        print(\"----- Entering wait loop ------\")\n",
    "        urlSuffix='/v4/reference_data_sets/' + artifact_id + '/versions/' + version_id + '/value_imports/' + import_id\n",
    "        headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "        workflow_id = r.json()[\"workflow_id\"]\n",
    "\n",
    "        while True :\n",
    "            r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "            if r.status_code != 200 :\n",
    "                print(\"Error with the request. Code: \", r.status_code)\n",
    "                print(r.text)\n",
    "                break\n",
    "            status = r.json()[\"import_info\"][\"import_state\"]\n",
    "            if status != \"IN_PROGRESS\" :\n",
    "                break\n",
    "            else :\n",
    "                print (\"Import in progess, please wait\")\n",
    "                time.sleep(5)\n",
    "        print(\"Import finished. Status = \", r.status_code)\n",
    "    else :\n",
    "        print(\"Error with the request. Code: \", r.status_code)\n",
    "        print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.b. Publish the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Load Position Lookup Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.a. Add the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"---- Load Position Lookup Data from CSV----\")\n",
    "\n",
    "IMPORT_CSV_FILE = \"artifacts/governance-reference-position.csv\"\n",
    "IMPORT_CSV_FILE = LOCAL_DIR_PREFIX + IMPORT_CSV_FILE\n",
    "\n",
    "artifact_id = None\n",
    "version_id = None\n",
    "urlSuffix='/v3/governance_artifact_types/reference_data?workflow_status=published&limit=200'\n",
    "headers = {\"accept\": \"application/json\" ,\"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    for i in r.json()[\"resources\"] :\n",
    "        if i[\"name\"] == \"Position Lookup\" :\n",
    "            artifact_id = i[\"artifact_id\"]\n",
    "            version_id = i[\"version_id\"]\n",
    "            print(\"artifact_id = \", artifact_id, \" version_id = \" , version_id)\n",
    "            break\n",
    "else :\n",
    "    print(\"Error in retrieving reference data artifacts, Code = \", r.status_code)\n",
    "    print(r.text)\n",
    "\n",
    "if artifact_id is None or version_id is None:\n",
    "    print(\"Position Lookup not found\")\n",
    "else :    \n",
    "    urlSuffix='/v4/reference_data_sets/' + artifact_id + '/versions/' + version_id + '/value_imports'\n",
    "    headers = {\"Authorization\" : \"Bearer \" + access_token }\n",
    "    import_parameters = {\n",
    "        \"artifact_id_mode\": False,\n",
    "        \"code\": \"POSITION_CODE\",\n",
    "        \"first_row_header\": True,\n",
    "        \"import_relationships_only\": False,\n",
    "        \"skip_workflow_if_possible\": False, \n",
    "        \"trim_white_spaces\": True,\n",
    "        \"value\": \"POSITION_EN\",\n",
    "        \"value_conflicts\": \"OVERWRITE\" \n",
    "    }\n",
    "    files={\n",
    "        'import_csv_file'   : ('import_csv_file', open(IMPORT_CSV_FILE,'rb') ),\n",
    "        'import_parameters' : (None, str(import_parameters))   \n",
    "    }\n",
    "    \n",
    "    r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, files=files)\n",
    "\n",
    "    if r.status_code == 202 :\n",
    "        import_id = r.json()[\"import_info\"][\"import_id\"]\n",
    "        print(f\"----- Import process started: {import_id} ----- \")\n",
    "        print(\"----- Entering wait loop ------\")\n",
    "        urlSuffix='/v4/reference_data_sets/' + artifact_id + '/versions/' + version_id + '/value_imports/' + import_id\n",
    "        headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "\n",
    "        workflow_id = r.json()[\"workflow_id\"]\n",
    "\n",
    "        while True :\n",
    "            r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "            if r.status_code != 200 :\n",
    "                print(\"Error with the request. Code: \", r.status_code)\n",
    "                print(r.text)\n",
    "                break\n",
    "            status = r.json()[\"import_info\"][\"import_state\"]\n",
    "            if status != \"IN_PROGRESS\" :\n",
    "                break\n",
    "            else :\n",
    "                print (\"Import in progess, please wait\")\n",
    "                time.sleep(5)\n",
    "        print(\"Import finished. Status = \", r.status_code)\n",
    "    else :\n",
    "        print(\"Error with the request. Code: \", r.status_code)\n",
    "        print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.b. Publish the draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlSuffix='/v3/workflows/' + workflow_id + '?include_user_tasks=true'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "r = requests.get(myconn.urlRequest(urlSuffix), headers=headers)\n",
    "\n",
    "user_tasks = r.json()[\"entity\"][\"user_tasks\"]\n",
    "for i in user_tasks :\n",
    "    if i[\"metadata\"][\"workflow_id\"] == workflow_id :\n",
    "        task_id = i[\"metadata\"][\"task_id\"]\n",
    "\n",
    "urlSuffix='/v3/workflow_user_tasks/' + task_id + '/actions'\n",
    "headers = {\"accept\": \"application/json\", \"Authorization\" : \"Bearer \" + access_token}\n",
    "payload = {'action': 'complete', 'form_properties': [{'id': 'action', 'value': '#publish'}]}\n",
    "r = requests.post(myconn.urlRequest(urlSuffix), headers=headers, json=payload)\n",
    "\n",
    "if r.status_code == 202 or r.status_code == 204 :\n",
    "    print(\"Publish Successful, Code = \", r.status_code)\n",
    "else :\n",
    "    print(\"Error in publishing artifacts, Code = \", r.status_code)\n",
    "    print(r.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
